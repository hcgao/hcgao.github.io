<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>IJCAI 2025 Tutorial: Distributed Stochastic Nested Optimization for Emerging Machine Learning Models</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-89918118-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="student.html">Students</a></div>
<div class="menu-item"><a href="services.html">Services</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>IJCAI 2025 Tutorial: Distributed Stochastic Nested Optimization for Emerging Machine Learning Models</h1>
</div>
<ul>
<li><p>Date: TBD</p>
</li>
<li><p>Time: TBD</p>
</li>
<li><p>Location:  TBD</p>
</li>
</ul>
<h2>Overview</h2>
<div class="infoblock">
<div class="blockcontent">
<p>Federated Learning has attracted significant attention in recent years, resulting in the development of numerous methods. 
However, most of these methods focus solely on traditional minimization problems and fail to address new learning paradigms in machine learning. 
Therefore, this tutorial focuses on the learning paradigm that can be formulated as the stochastic compositional optimization (SCO) problem and the stochastic bilevel optimization (SBO) problem, 
as they cover a wide variety of machine learning models beyond traditional minimization problem, such as model-agnostic meta-learning, imbalanced data classification models, 
contrastive self-supervised learning models, graph neural networks, neural architecture search, etc.  
The compositional structure and bilevel structures bring unique challenges in computation and communication for federated learning. 
To address these challenges, a series of federated compositional optimization and federated bilevel optimization methods have been developed in the past few years. 
However,  these advances have not been widely disseminated.  Thus, this tutorial aims to introduce the unique challenges,  recent advances, and practical applications of federated SCO and  SBO. 
The audience will benefit from this tutorial by gaining a deeper understanding of federated SCO and SBO algorithms and learning how to apply them to real-world applications.</p>
</div></div>
<h2>Tutorial Outline</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p>Section I:  Section I: Introduction (15 min). <br /></p>
</li>
</ul>
<ul>
<li><p>Section II:  Federated  Compositional Optimization (35 min). <br /></p>
</li>
</ul>
<ul>
<li><p>Section III:  Federated  Bilevel Optimization (35 min). <br /></p>
</li>
</ul>
<ul>
<li><p>Section IV: Summary and Future Directions (10 min). <br /></p>
</li>
</ul>
</div></div>
<h2>Presenters</h2>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="photo.JPG" alt="alt text" width="120px" height="140px" /></a>&nbsp;</td>
<td align="left"><p><b>Hongchang Gao</b> is an assistant professor in the Department of Computer and Information Sciences at Temple University. His research interests include machine learning, optimization, and biomedical data science, with a special focus on distributed optimization and federated learning. 
His work has been published in top venues such as ICML, NeurIPS, AISTATS, KDD, AAAI, and IJCAI. He currently serves as an Associate Editor for the Journal of Combinatorial Optimization and regularly acts as an Area Chair for ICML and NeurIPS. 
He is a recipient of the NSF CAREER Award (2024), the AAAI New Faculty Highlights (2023), and the Cisco Faculty Research Award (2023).</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="xinwen.jpg" alt="alt text" width="135px" height="140px" /></a>&nbsp;</td>
<td align="left"><p><b>Xinwen Zhang</b> is a Ph.D. student in the Department of Computer and Information Sciences at Temple University. 
Her research primarily focuses on stochastic minimax optimization and stochastic compositional optimization, as well as their applications to real-world data mining tasks. 
She has published multiple pioneering works on federated compositional optimization in top machine learning venues, such as ICML and NeurIPS.</p>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-09 20:32:52 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=EtsHne_TmseW5ch0xFRAaUP05lfRyCetP-g76VSS0gA"></script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("|");
    pageTracker._trackPageview();
} catch(err) {}</script>
</body>
</html>

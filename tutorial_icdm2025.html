<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>ICDM 2025 Tutorial: Federated Stochastic Compositional and Bilevel Optimization</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-89918118-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="student.html">Students</a></div>
<div class="menu-item"><a href="services.html">Services</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>ICDM 2025 Tutorial: Federated Stochastic Compositional and Bilevel Optimization</h1>
</div>
<ul>
<li><p>Date: Nov 13, 2025</p>
</li>
<li><p>Time: 14:00 - 15:50</p>
</li>
<li><p>Location:  Ohio</p>
</li>
</ul>
<h2>Overview</h2>
<div class="infoblock">
<div class="blockcontent">
<p>In recent years, Federated Learning has emerged as a rapidly growing area of research, sparking the development of a wide range of algorithmic approaches. 
Yet, the majority of these efforts have been confined to tackling conventional optimization problems, often overlooking the broader machine learning paradigms. 
This tutorial shifts the focus to two increasingly important  problem formulations: stochastic compositional optimization (SCO) and stochastic bilevel optimization (SBO). 
These frameworks encompass a variety of advanced learning scenarios that go well beyond standard objective minimization, including model-agnostic meta-learning, classification with imbalanced data, contrastive self-supervised learning, graph-based neural models, and neural architecture search.
The inherently nested  structure of SCO and SBO pose unique challenges, particularly in the  Federated Learning setting, where both computational and communication constraints must be carefully managed. 
In response, a new line of research has emerged, aiming to adapt and extend optimization techniques to the federated setting for these complex problems. 
Despite this progress, the resulting methodologies remain relatively underexplored in the broader machine learning and data mining communities. 
This tutorial seeks to bridge that gap. We will provide a comprehensive overview of the theoretical foundations, algorithmic innovations, and practical applications of federated SCO and SBO. 
Participants will leave with a clear understanding of the challenges unique to these problems, the latest techniques developed to address them, and actionable insights on applying these methods to real-world federated learning applications.</p>
</div></div>
<h2>Tutorial Outline</h2>
<div class="infoblock">
<div class="blockcontent">
<ul>
<li><p>Section I: Introduction (15 minutes).  [<a href="https://drive.google.com/file/d/1J4m0q2M-MzbyFCWSERYm7hMSKbXM1f6Y/view?usp=sharing">Slides</a>] <br /> </p>
</li>
</ul>
<ul>
<li><p>Section II:  Federated Stochastic Compositional Optimization (30 minutes).  [<a href="https://drive.google.com/file/d/1dyCiu1Yq4UALVflctb-u8xJzAYGXGDVL/view?usp=sharing">Slides</a>] <br /> </p>
</li>
</ul>
<ul>
<li><p>Break (10 minutes) <br /></p>
</li>
</ul>
<ul>
<li><p>Section III: Federated AUC Maximization (25 minutes).  [<a href="https://drive.google.com/file/d/1A38pp2vkPshqfs2_gA44-XxAuFjPReSJ/view?usp=sharing">Slides</a>] <br /> </p>
</li>
</ul>
<ul>
<li><p>Section IV: Federated Stochastic Bilevel Optimization (25 minutes).   [<a href="https://drive.google.com/file/d/1-1TouonxP9p7J7ELdWUF9jDgO4nDZxQ2/view?usp=sharing">Slides</a>] <br /> </p>
</li>
</ul>
<ul>
<li><p>Section V: Summary and Future Directions (5 minutes).  [<a href="https://drive.google.com/file/d/13WZCtQv6GNFQh7WoidDtPqRqa47zx8Nq/view?usp=sharing">Slides</a>] <br /> </p>
</li>
</ul>
</div></div>
<h2>Presenters</h2>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="photo.JPG" alt="alt text" width="120px" height="140px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://hcgao.github.io/index.html"><b>Hongchang Gao</b></a> is an assistant professor in the Department of Computer and Information Sciences at Temple University. His research interests include machine learning, optimization, and biomedical data science, with a special focus on distributed optimization and federated learning. 
His work has been published in top venues such as ICML, NeurIPS, AISTATS, KDD, AAAI, and IJCAI. He currently serves as an Associate Editor for the Journal of Combinatorial Optimization and regularly acts as an Area Chair for ICML and NeurIPS. 
He is a recipient of the NSF CAREER Award (2024), the AAAI New Faculty Highlights (2023), and the Cisco Faculty Research Award (2023).</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<a href="IMGLINKTARGET"><img src="xinwen2.jpg" alt="alt text" width="120px" height="150px" /></a>&nbsp;</td>
<td align="left"><p><a href="https://xinwenzhang99.github.io/"><b>Xinwen Zhang</b></a> is a Ph.D. student in the Department of Computer and Information Sciences at Temple University. 
Her research primarily focuses on stochastic minimax optimization and stochastic compositional optimization, as well as their applications to real-world data mining tasks. 
She has published multiple pioneering works on federated compositional optimization in top machine learning venues, such as ICML and NeurIPS. She is a recipient of KDD 2023 Student Travel Award, NeurIPS 2023 Scholar Award, WiML 2023 Travel Award, ICML 2024 Travel Award, ICDM 2025 Student Travel Award, and ICDM Female Student Award in Data Science.</p>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2025-11-13 13:37:02 EST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=EtsHne_TmseW5ch0xFRAaUP05lfRyCetP-g76VSS0gA"></script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("|");
    pageTracker._trackPageview();
} catch(err) {}</script>
</body>
</html>
